#+setupfile: ../../lvl-2.org
#+title: Speeding up CircleCI tests for a Python Django project
#+begin_abstract
I discuss how we reduced the time to run one of my employer's Django
application CircleCI test suites from about 13 minutes to under 4
minutes.
#+end_abstract
#+category: Python
#+category: CircleCI

My employer use CircleCI to run all tests on every Pull Request (PR)
for our applications. In April these tests for one such Python Django
application's PR workflow took about 13 minutes to run on CircleCI. We
aimed to reduce this time to under 10 minutes. (Faster tests means
faster feedback cycles, which means you can ship more often. Shipping
more often in turn means you gain more confidence shipping---it's a
virtuous cycle.) We got the tests to finish in under 4 minutes. This
post discusses how.

#+toc: headlines 1

* Introduction

  Picture [[april]] shows part of our workflow at the start of our story.
  The =build= job creates a Docker image, containing only runtime
  dependencies[fn::We don't want to add test dependencies to the base
  image, as on the main branch we deploy this on ElasticBeanstalk.].
  It dumps this to a file with =docker save= that it persists in a
  workspace[fn::A workspace is a workflows-aware storage mechanism. It
  stores data unique to the job, that downstream jobs can use.]. The
  two tests jobs[fn::We run two test jobs because we deploy this
  application in two separate configurations with different feature
  sets.] attaches the workspace, restores the base image and extends
  this to create an image with all the extra modules required to run
  the tests, starts dependencies, and runs the tests.

  #+name: april
  #+caption: April Workflow (13m 24s)
  file:speed-up-circleci/wf-april.png
  # https://circleci.com/workflow-run/f54145e7-1cbd-415d-90c0-ce7047bdcfbe

* Analysing the problem space

  Doing shared setup once, then fanning out like this is a
  time-honoured way to reduce resource usage. However our attempts to
  reduce duplication---saving the base image to workspace in the build
  job, as well as /restoring/ this docker image in the two
  =test_lp{eu,usa}= jobs---was more time consuming than we had liked.

  We use [[https://circleci.com/docs/2.0/docker-layer-caching/][Docker Layer Caching (DLC)]] on our PR branches, so---if PRs
  don't change runtime dependencies---building the base docker image
  itself was usually pretty fast. However:

  - Issuing =docker save= to dump the built image to a file took around
    30 seconds, and [[https://circleci.com/docs/2.0/configuration-reference/#persist_to_workspace][persisting it to the workspace]] for later jobs
    added 60.

  - The =test_lp{usa,eu}= jobs then had to [[https://circleci.com/docs/2.0/configuration-reference/#attach_workspace][attach the workspace]] and load
    this base image, adding another 30 seconds.

  - Our test jobs mimiced the way most local devs work, starting
    dependencies (Redis, Cassandra, and PostgreSQL) with
    =docker-compose=. This required us to use the [[https://circleci.com/docs/2.0/executor-types/][machine executor]],
    which added about 30-60 second startup overhead compared to the
    docker executors.

  - Because the base image from the =build= job contained only runtime
    dependencies, we had to build a /test/ docker image, extending the
    base to add dependencies for testing. (Another 70-ish seconds.)

  - Finally, running the tests took about 6 minutes 30 seconds.

  It started to look like our shared =build= job was an obstacle to
  speeding up our tests, rather than a vehicle for it.

* Discussion

  This workflow mimiced how most of our engineers used =docker-compose=
  for local development, building a service image with all runtime
  dependencies, and a test image that extended that with tests and
  test dependencies. But not /all/ our engineers did that. It was
  possible to run the tests locally directly with Tox. Indeed we
  considered this the core "test API", and our Dockerfiles used tox
  internally. This would be key to the solution.

  #+name: june
  #+caption: June Workflow (3m 48s)
  file:speed-up-circleci/wf-june.png
  # https://circleci.com/workflow-run/0163111c-a34a-4bc5-9a1c-34ed32210bc5

* How did we achive this?

  In a CI context you want to run all the tests in a freshly created
  environment with all the latest dependencies. Locally you won't
  typically create a new virtualenv and install dependencies anew
  every time you run tests, and you're more likely to cherry-pick
  relevant tests to run than run them all every time.

  We changed the CI test workflow to no longer depend on building the
  base image[fn::We still build it, because we want to test that we
  can, since we use it in our deploy workflow still. But we no longer
  need to save it to disk or persist it to the workspace for our
  PRs.]. Instead we install both runtime and test dependencies into
  the main container, and run tests directly. This meant we did more
  work: we installed the runtime dependencies twice. However, we
  avoided more minutes of saving the image to & restoring it from our
  workspace.

  At the same time we moved to launch auxiliary services using
  CircleCI's Docker executor, using its native [[https://circleci.com/docs/2.0/configuration-reference/#docker--machine--macosexecutor][service container
  support]] rather than docker-compose. This move meant we avoided the
  extra startup-cost of the =machine= executor.

  Installing dependencies in the primary container on CircleCI, rather
  than relying on our Dockerfile, allowed us to use [[https://circleci.com/docs/2.0/language-python/#cache-dependencies][CircleCI's caching]]
  to speed up virtualenv creation[fn::In contrast to their example,
  however, we cache only PIP downloads, rather than the fully-built
  virtualenv. This to avoid any contamination that could creep into
  the virtualenv over time.]. We didn't have access to this shared
  cache when building docker images, but now it saved about 90 seconds
  when building the virtualenv.

  Moreover, on CI we don't need to keep the DB after test runs for
  debugging. Thus we were able to replace the DB image we used for
  tests with an [[https://circleci.com/docs/2.0/databases/][in-memory Postgres image]], that doesn't save to disk.
  This gave us another small speed boost.

  By now we had the total run time down to about six minutes. This was
  already a great improvement, and most of this time was now from
  running the tests themselves. Could we speed this up more though?

  I tried running tests in parallel, using Django's test runner.
  Unfortunately this resulted in lots of test failures related to our
  Cassandra integration[fn::I then tried using CircleCI's [[https://circleci.com/docs/2.0/parallelism-faster-jobs/#splitting-test-files][test
  splitting]] instead. This showed promise, but it had problems: it was
  difficult to achive an even split of the test files, since Django's
  test runner only accepts test classes. It was also more expensive,
  since we used more containers. However, it prompted one of my
  colleagues to take a hard look at /why/ the tests failed when running
  in parallel using Django's native method.]. Handily a colleague was
  able to fix the problem. After a bit of trial and error we settled
  on running the tests in parallel across 3 CPUs. The entire PR
  workflow (Figure [[june]]) now as a rule completes in under four
  minutes---sometimes closer to three. Less time than the old workflow
  spent /preparing/ to start running the tests!

** Upgrading to the CircleCI Performance plan for 3+ CPUs executors

   By default CircleCI gives you only 2 CPUs, but by upgrading to their
   new [[https://circleci.com/pricing/usage/][Performance Plan]] we were able to specify different [[https://circleci.com/docs/2.0/configuration-reference/#resource_class][resource
   classes]] for our jobs. This plan even saves us about one third off
   our monthly CircleCI bill! How? We hate queueing and on the old plan
   paid CircleCI for many containers. Most of our engineers are
   primarily based in one region, and all the containers were idle at
   night and all weekend. Paying for what we /use/ makes so much more
   sense!



* Conclusion

  We managed to reduce the run-time of our PR tests from around 13
  minutes to under 4. There was no single change that gave a massive
  reduction on its own. Neither did we expect it to! Running tests in
  parallel would not have helped much when we spent most of the time
  /preparing/ to run the tests. However, by nudging our CI test setup
  towards simplicity, and playing to the strength of the platform, we
  were able to iterate and unlock ways to improve further.
