#+setupfile: ../../lvl-2.org
#+title: Speeding up CircleCI tests for a Python Django project
#+begin_abstract
I show how we reduced the runtime of a Python & Django application's
CircleCI workflow from 15 minutes to under 4 minutes.
#+end_abstract
#+category: Python
#+category: CircleCI

My employer use CircleCI to run tests on every pull request (PR) for
our applications. Three months ago these tests for one such Python
Django application's PR workflow took over 15 minutes[fn::Down from /40
minutes/ a year or so ago.] to run on CircleCI. One of my team's
OKRs[fn::[[http://objectives-key-results.com/][Objectives and Key Results]].] was to reduce the build/test
feedback cycle for PRs to under 10 minutes. With a bit of
out-of-the-box thinking we managed to get the full PR suite for this
project down to under 4 minutes.

#+toc: headlines 1

Picture [[march]] shows a typical PR workflow in March 2019[fn::We deploy
the application in two different configurations, for two independent
markets: EU and US. These deployments do not interact. To be safe we
run the full test suite for each configuration, for each skipping only
the tests we know are not applicable for that profile, about 10% of
the total.]. It wasn't uncommon for it to take over 15 minutes,
though it sometimes ran a bit faster.

#+name: march
#+caption: March Workflow (15m 29s)
[[file:speed-up-circleci/wf-march.png]]
# https://circleci.com/workflow-run/8e8e56da-f6ab-45f6-a36b-7ee8419131fa

* Introducing clarity of auxiliary tests

  The =code_checks_and_build_docs= job ran lots of different steps for
  =flake8=, =shellcheck=, =gjslint=, =isort= etc. The problem was that if any
  one of these failed, the rest would not run. It also wasn't always
  easy to find out /which/ step was failing, and we had trawl through
  lots of build output to find out. Finally, we had to wait a long
  time to find out if they were all successful.

  We split it into separate jobs run concurrently, addressing all
  these shortcomings. Doing so we realised that none of them needed to
  wait for the =build= job to finish. Picture [[april]] shows the resulting
  workflow. Though the /total/ time improved a little, I think that was
  down to luck. More importantly we get more useful information
  sooner. The slowest of the new jobs now finish after about two
  minutes, before the build job even finishes. If any of these new
  jobs fail, it's obvious which one without even opening the CircleCI
  console---it's encoded in the name of the job!

  #+name: april
  #+caption: April Workflow (13m 24s)
  file:speed-up-circleci/wf-april.png
  # https://circleci.com/workflow-run/f54145e7-1cbd-415d-90c0-ce7047bdcfbe

* Reducing Total Runtime

  Next we wanted to reduce the total time to run the PR workflow to
  under 10 minutes. The setup using a shared =build= job was one of the
  key blockers for this. It turns out our attempts to reduce
  duplication---by building & saving a base docker image we would
  later use to run the tests in the =build= job, as well as /restoring/
  this docker image in the two =test_lp{eu,usa}= jobs---was more time
  consuming than we had expected:

  - We use [[https://circleci.com/docs/2.0/docker-layer-caching/][Docker Layer Caching (DLC)]] on PR branches, so if your PR
    didn't change runtime dependencies building the docker image was
    usually pretty fast. In our deploy workflow (not discussed here)
    we run a container of this image on ElasticBeanstalk, so we don't
    add test dependencies to it.

  - However, a =docker save= to a file on disk took around 30 seconds,
    and because the resulting file is rather big [[https://circleci.com/docs/2.0/configuration-reference/#persist_to_workspace][persisting it to the
    workspace]] for later jobs added another minute.

  - The =test_lp{usa,eu}= jobs had to [[https://circleci.com/docs/2.0/configuration-reference/#attach_workspace][attach the workspace]] and load our
    base image, adding 30 seconds.

  - These test jobs also mimiced the way most local devs work,
    manually started up dependencies (Redis, Cassandra, and
    PostgreSQL) with =docker-compose=. This required us to use the
    [[https://circleci.com/docs/2.0/executor-types/][machine executor]], which added about 30-60 second startup overhead
    compared to the docker executors.

  - Because the base image from the =build= job contained only runtime
    dependencies, we had to build a /test/ docker image, extending the
    base to add dependencies for testing. (Another 70-ish seconds.)

  - Finally, running the tests took about 6 minutes 30 seconds.

  We attacked this problem from multiple angles, and from figure [[june]]
  you can see our current workflow's /total/ run time is now under 4
  minutes. Our tests now usually finish in less time than the old
  workflow spent /preparing to start/ running our tests!

  #+name: june
  #+caption: June Workflow (3m 48s)
  file:speed-up-circleci/wf-june.png
  # https://circleci.com/workflow-run/0163111c-a34a-4bc5-9a1c-34ed32210bc5

* How did we achive this?

  Most of our engineers used =docker-compose= for local development,
  building a service image with all runtime dependencies, and a test
  image that extended that with tests and test dependencies. But not
  all. It was possible to run the tests locally directly with Tox.
  (Our Dockerfiles used tox internally.)

  In a CI context you want to run all the tests in a freshly created
  environment with all the latest dependencies. Locally you won't
  typically create a new virtualenv and install dependencies anew
  every time you run tests, and you're more likely to cherry-pick
  relevant tests to run than run them all every time.

  We changed the CI test workflow to no longer depend on building the
  base image[fn::We still build it, because we want to test that we
  can, since we use it in our deploy workflow still. But we no longer
  need to save it to disk or persist it to the workspace for our
  PRs.]. Instead we install both runtime and test dependencies into
  the main container, and run tests directly. This meant we did more
  work: we installed the runtime dependencies twice. However, we
  avoided more minutes of saving the image to & restoring it from our
  workspace.

  At the same time we moved to launch auxiliary services using
  CircleCI's Docker executor, using its native [[https://circleci.com/docs/2.0/configuration-reference/#docker--machine--macosexecutor][service container
  support]] rather than docker-compose. This move meant we avoided the
  extra startup-cost of the =machine= executor.

  Installing dependencies in the primary container on CircleCI, rather
  than relying on our Dockerfile, allowed us to use [[https://circleci.com/docs/2.0/language-python/#cache-dependencies][CircleCI's caching]]
  to speed up virtualenv creation[fn::In contrast to their example,
  however, we cache only PIP downloads, rather than the fully-built
  virtualenv. This to avoid any contamination that could creep into
  the virtualenv over time.]. We didn't have access to this shared
  cache when building docker images, but now it saved about 90 seconds
  when building the virtualenv.

  Moreover, on CI we don't need to keep the DB after test runs for
  debugging. Thus we were able to replace the DB image we used for
  tests with an [[https://circleci.com/docs/2.0/databases/][in-memory Postgres image]], that doesn't save to disk.
  This gave us another small speed boost.

  By now we had the total run time down to about six minutes. This was
  already a great improvement, and most of this time was now from
  running the tests themselves. Could we speed this up more though?

  I tried running tests in parallel, using Django's test runner.
  Unfortunately this resulted in lots of test failures related to our
  Cassandra integration[fn::I then tried using CircleCI's [[https://circleci.com/docs/2.0/parallelism-faster-jobs/#splitting-test-files][test
  splitting]] instead. This showed promise, but it had problems: it was
  difficult to achive an even split of the test files, since Django's
  test runner only accepts test classes. It was also more expensive,
  since we used more containers. However, it prompted one of my
  colleagues to take a hard look at /why/ the tests failed when running
  in parallel using Django's native method.]. Handily a colleague was
  able to fix the problem. After a bit of trial and error we settled
  on running the tests in parallel across 3 CPUs. The entire PR
  workflow now as a rule completes in under four minutes---sometimes
  closer to three.

** Upgrading to the CircleCI Performance plan for 3+ CPUs executors

   By default CircleCI gives you only 2 CPUs, but by upgrading to their
   new [[https://circleci.com/pricing/usage/][Performance Plan]] we were able to specify different [[https://circleci.com/docs/2.0/configuration-reference/#resource_class][resource
   classes]] for our jobs. This plan even saves us about one third off
   our monthly CircleCI bill! How? We hate queueing and on the old plan
   paid CircleCI for many containers. Most of our engineers are
   primarily based in one region, and all the containers were idle at
   night and all weekend. Paying for what we /use/ makes so much more
   sense!

* Conclusion

  We managed to reduce the run-time of our PR tests from around 13
  minutes to under 4. There was no single change that gave a massive
  reduction on its own. Neither did we expect it to! Running tests in
  parallel would not have helped much when we spent most of the time
  /preparing/ to run the tests. However, by nudging our CI test setup
  towards simplicity, and playing to the strength of the platform, we
  were able to iterate and unlock ways to improve further.

