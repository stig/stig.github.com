#+setupfile: ../../lvl-2.org
#+title: Speeding up CircleCI tests for a Python project by caching less and doing more things in parallel
#+begin_abstract
I show how we reduced the runtime of a Python & Django application's
CircleCI workflow from 15 minutes to under 4 minutes.
#+end_abstract
#+category: Python
#+category: CircleCI

My employer use CircleCI to run tests on every pull request (PR) for
our applications. Three months ago these tests for one such Python
Django application's PR workflow took over 15 minutes to run on
CircleCI. One of my team's OKRs[fn::[[http://objectives-key-results.com/][Objectives and Key Results]].] was
to reduce the build/test feedback cycle for PRs to under 10 minutes.
With a bit of out-of-the-box thinking we managed to get the full PR
cycle for this project down to under 4 minutes.

We deploy the application in two different configurations, for two
independent markets: EU and US[fn::These deployments do not
interact.]. To be safe we run the full test suite for each
configuration, skipping the tests we know are unapplicable for each
profile[fn::About 10% of the total.]. Partly for this reason we had a
common =build= job to create a common Docker image to run tests inside.
This job took a while to run, and tests would even start running
before it finished. More on that later.

Picture [[march]] shows a typical PR workflow in March 2019. It wasn't
uncommon for it to take over 15 minutes, though they sometimes ran a
bit faster.

@@html:<div class="row"><div class="column">@@

#+name: march
#+caption: CircleCI PR workflow March 2019 (15m 29s)
[[file:speed-up-circleci/wf-march.png]]
# https://circleci.com/workflow-run/8e8e56da-f6ab-45f6-a36b-7ee8419131fa

The =code_checks_and_build_docs= job ran lots of different steps for
=flake8=, =shellcheck=, =gjslint=, =isort= etc. The problem was that if any
one of these failed, the rest would not run. It also wasn't always
easy to find out /which/ step was failing, and we had trawl through lots
of build output to find out. Finally, we had to wait until the last
had run to find out if they were all successful. By splitting it into
separate jobs they can run concurrently, addressing all these
shortcomings. Additionally, we realised that they actually didn't need
to wait for the =build= job to finish.

Picture [[april]] shows the resulting workflow. The total time has not
improved by much yet, but we get more useful information much sooner.
The slowest of the new jobs now finish after about two minutes, before
the build job even finishes.

@@html:</div><div class="column">@@

#+name: april
#+caption: CircleCI PR workflow April 2019 (13m 24s)
[[file:speed-up-circleci/wf-april.png]]
# https://circleci.com/workflow-run/f54145e7-1cbd-415d-90c0-ce7047bdcfbe

New we wanted to address the total time taken to run the tests.
Because we run tests separately for two profiles we had a common =build=
job to create a common Docker image to run tests inside, among other
things. This job took a while to run, and tests would even start
running before it finished.


@@html:</div><div class="column">@@

#+name: june
#+caption: CircleCI PR workflow June 2019 (3m 48s)
[[file:speed-up-circleci/wf-june.png]]
# https://circleci.com/workflow-run/0163111c-a34a-4bc5-9a1c-34ed32210bc5

@@html:</div></div>@@
